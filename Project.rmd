---
title: 'STAT 151A Project'
subtitle: 'Predicting Housing Resale Prices in Singapore'
date: "April 10th 2024"
author: "Michelle Vuong, Celina Mac, Lewis Chong"
output:
  pdf_document: default
  html_document: default
---

## Introduction

According to the Federal Reserve Board of the United States, the effects of the COVID-19 pandemic on the U.S. housing market have led to a rapid increase in housing prices with almost \$9 trillion in the wealth of owner occupied housing between the years 2020-2022. From the perspective of a prospective homeowner, the median housing price in the United States has nearly tripled between 1992 to 2021 with the largest spike in housing prices occurring during after the pandemic.

This consequence of the pandemic is not unique to the United States economy and instead, is omnipresent all throughout the world. With the effects of the pandemic taken into consideration, we are motivated by this recent event to see how the theory of linear modelling could be applied in order to better understand how it affects the price of housing across a large population. In particular, we aim to do this with a country that is smaller relative to the United States on the country of Singapore. Throughout this report, we will attempt to understand the effects of COVID-19 and housing prices utilizing techniques such as linear regression, ridge and lasso models, and the model's effectiveness using cross-validation.

## Problem Description

Our research objective is to gain understanding of the effect COVID-19 had on the Singaporean housing market. We aim to create an efficient and concise model that gives us an answer to the question: how do the resale prices differ between the years of 2017-2019 and 2020-2022? In addition, we will analyze the original set of housing metric indicators provided from the data set given to us from Kaggle and determine if we can refine the number of indicators to a minimum. Making use of statistical analysis techniques such as Ridge and Lasso regularization, we aim to extract the most important predictors that can still effectively provide us an understanding of the resale prices of Singaporean homes.

## Data

Our data collection process began with an open web research on the housing markets of Singapore. We landed on Kaggle, an open source hub of public data sets uploaded by public users, which can be used for data exploration, building predictive models, and general practice with real-world data. Specifically, our data from Kaggle was transcribed by a user from the Singapore Government Agency Website that studied Resale flat prices based on registration date from Jan-2017 onwards. Data was collected by the Housing and Development Board, commonly referred to as "HDB". It is a statutory board of the Ministry of National Development in Singapore and it seeks to provide support in homeownership and ease in rental processes for residents. Simultaneously as the HDB are providing aid, they are collecting data on what home are being bought, built, and sold for. As this government established board provides public housing for more than 80% of Singapore's population, this project will make the assumption that all data was collected as a random sample of Singapore's population and data quality is up to par with research standards.

### EDA + Data Preprocessing

We will begin with Exploratory Data Analysis to understand the data that we are working with.

```{r libraries, include=FALSE}

library(MASS)
library(glmnet)
if (!requireNamespace("caret", quietly = TRUE)) {
  # If not installed, install the package
  install.packages("caret")
}
if (!requireNamespace("corrplot", quietly = TRUE)) {
  # If not installed, install the package
  install.packages("corrplot")
}
library(corrplot)
library(caret)
library(tidyverse)
library(gridExtra)

housing <- read_csv("Resale_Price_2017_2022.csv",show_col_types=FALSE)
```

### Data Inspection

```{r}
#NA values in cols
na_counts <- colSums(is.na(housing))

# 
any_na <- any(na_counts > 0)

cat("Datasets contains NA values : ",any_na)
```

There are no null values in the dataset, so it is clean.

```{r}
glimpse(housing)
```

Upon our first inspection of the data, we will be using the `resale_price` as the response variable, and the columns `flat_type,floor_area_sqm,remaining_lease,town` to serve as the predictors.

```{r}
housing <- housing %>% dplyr::select(month,town,flat_type,floor_area_sqm,
                              remaining_lease,resale_price) %>% 
            mutate(month = parse_date(month,format="%Y-%m"))

```

#### 1. One-hot-encoding

From the above summary, we see that the `flat_type` is a categorical variable. Thus,we will be apply one hot encoding on it for the model to regress.

```{r}
housing <- housing %>%
  mutate(
    is_2_room = ifelse(flat_type == "2 ROOM", 1, 0),
    is_3_room = ifelse(flat_type == "3 ROOM", 1, 0),
    is_4_room = ifelse(flat_type == "4 ROOM", 1, 0),
    is_5_room = ifelse(flat_type == "5 ROOM", 1, 0),
    is_executive = ifelse(flat_type == "EXECUTIVE", 1, 0),
    is_1_room = ifelse(flat_type == "1 ROOM", 1, 0),
    is_multi_generation = ifelse(flat_type == "MULTI-GENERATION", 1, 0)
  ) %>% 
  dplyr::select(!flat_type)


```

Also, we noted that for `town`, there is too many distinct values:

```{r}
cat("Distinct values for `town` :",length(unique(housing$town)))
```

Thus, we will categorize the different towns of Singapore into NSEW regions, and further apply one-hot encoding as done above.

```{r}

# Function to categorize towns into NSEW regions
categorize_town <- function(town) {
  north <- c("ANG MO KIO", "SEMBAWANG", "SENGKANG", "WOODLANDS", "YISHUN","BISHAN")
  south <- c("BUKIT MERAH", "BUKIT TIMAH", "CENTRAL AREA", "QUEENSTOWN")
  east <- c("BEDOK", "MARINE PARADE", "PASIR RIS", "TAMPINES")
  west <- c("BUKIT BATOK", "BUKIT PANJANG", "CHOA CHU KANG", "CLEMENTI", "JURONG EAST", "JURONG WEST", "KALLANG/WHAMPOA", "PUNGGOL", "SENGKANG", "TOA PAYOH", "SERANGOON", "GEYLANG", "HOUGANG")
  
  if (town %in% north) {
    return("North")
  } else if (town %in% south) {
    return("South")
  } else if (town %in% east) {
    return("East")
  } else if (town %in% west) {
    return("West")
  } else {
    return("Other")
  }
}

# Add a new column for NSEW region
housing <- housing %>%
  rowwise() %>%
  mutate(region = categorize_town(toupper(town))) %>% 
  mutate(
    is_north = ifelse(region == "North", 1, 0),
    is_south = ifelse(region == "South", 1, 0),
    is_west = ifelse(region == "West", 1, 0),
    is_east = ifelse(region == "East", 1, 0)
  ) %>% 
  dplyr::select(!region)

```

Note that for one-hot encoding on the columns `region` and `flat_type` , we can just drop one of the columns as it can be identified by the rest of the columns, i.e `(is_north,is_south,is_west) = (0,0,0)`corresponds to the house being in the East Region.

```{r}
housing <- housing %>% 
        dplyr::select(!c(is_east,is_multi_generation,town))

##
```

#### 2. Data Manipulation

We will be converting the `remaining_lease` column that contains how long the lease is to be of unit months instead of the current year+month.

```{r}

##Function to convert from years+ months to months
extract_months <- function(duration_str) {
    # Split into components
    components <- strsplit(duration_str, " ", perl = TRUE)[[1]]
    
    # Extract years and months (if available)
    years <- as.numeric(components[1])
    months <- ifelse(length(components) >= 3, as.numeric(components[length(components)-1]), 0)
    
    # Return total months
    return(years * 12 + months)
}

housing <- housing %>% 
            rowwise() %>%
            mutate(remaining_lease_mth = extract_months(remaining_lease)) %>% 
            dplyr::select(!remaining_lease)




```

#### 3. Standardizing Predictor Columns

```{r}
#Standardizing predictor columns
X <- housing %>% dplyr::select(floor_area_sqm,remaining_lease_mth) %>%
      scale() %>% as.data.frame()
colnames(X) <- c("floor_area_sqm_std","remaining_lease_std")

housing <- cbind(housing,X) %>% 
  dplyr::select(!c(remaining_lease_mth,floor_area_sqm))
```

```{r}
corr_mat<- cor(housing[sapply(housing, is.numeric)])
corrplot(corr_mat, method = "color", type = "upper", order ="hclust", 
         tl.col = "black", tl.srt = 45)
```

#### 4. Log transform

```{r}
id <- sample(nrow(housing),7000)
sample_housing <- housing[id,]

p1 <- ggplot(sample_housing) + 
        geom_point(aes(x=floor_area_sqm_std,y=resale_price),
                   size=0.5,position="identity") + 
        theme_minimal()
p2 <- ggplot(sample_housing) + 
        geom_point(aes(x=floor_area_sqm_std,y=log(resale_price)),
                   size=0.5,position="identity") + 
        theme_minimal()

grid.arrange(p1,p2,ncol=2,top="Comparison of log(resale_price) and resale_price")



```

We do a sample of 7000 on the original dataset, to argue that the increase of a small amount of floor area(sqm) doesn't result it a linear amount of resale price being added, but instead some non-linear increase in the price. This is equivalent to adding to a log of the resale prices. So we conclude that it results in better prediction if we do a regression on the log(resale price).

## Methods

In order to evaluate the most statistically significant housing metrics and reduce the number of predictors we have, we will use regularization. Beginning with Ridge Regularization:

```{r}

df <- housing %>% dplyr::select(!month)


ori <- lm(log(resale_price) ~ . + 0, data = df)

yhat <- predict(ori)

y <- log(df$resale_price)

MSE_ori <- mean((y-yhat)^2)
cat("MSE from the linear model: ", MSE_ori)

epsilon <- data.frame(resid=resid(ori),month=housing$month)

residuals_means <- epsilon %>%
  group_by(month) %>%
  summarise(mean_residual = mean(resid))

# Now you can plot the mean residuals against the months
ggplot(residuals_means, aes(x = month, y = mean_residual)) +
  geom_line() +
  labs(x = "Month", y = "Mean Residuals", title = "Mean Residuals Over Time")


```

Beta values very big, so we do regularization

```{r}

# Set seed for reproducibility
set.seed(123)

# Create an index for splitting the data
split <- createDataPartition(y = housing$resale_price, p = 0.8, list = FALSE)

# Split the data into training and test sets
train<- df[split, ]
test <- df[-split, ]

X_train <- train %>% dplyr::select(!resale_price)
y_train <- train$resale_price

# Fit Ridge model
ridge_model <- glmnet(x = X_train, y = y_train, alpha = 0)


# Extract coefficients from the ridge regression model
coefficients <- coef(ridge_model)


```

```{r}

# # Create an X matrix that represents the data frame above, but in linear perspective

# Perform Ridge regression
# ridge_model <- glmnet(X[,-ncol(X)], X[,ncol(X)], alpha = 0)
# #predictions <- predict.glm(ridge_model, newdata = X[,-ncol(X)])  # Adjust s (lambda) as needed
# 
# # Select the index with best lambda value.
# min_lambda <- ridge_model$lambda %>% 
#                 as.vector %>% 
#                     which.min
# best_lambda <- ridge_model$lambda[min_lambda]
# best_lambda
# 
# ridge_best <-  glmnet(X, y, alpha = 0,s=best_lambda)
```

### Subsetting our dataset

We will filter all dates before April 2020 as that was when the Singaporean government began enforcing preventive measures for the pandemic.

```{r}
pre_covid <- housing %>% 
  filter(month < "2020-04")

covid <- housing %>% 
  filter(month >= "2020-04")
```

## Results 

## Discussion 

### Limitations and Future Work

##### Reference
